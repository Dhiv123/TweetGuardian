# TweetShield ğŸ›¡ï¸  
**Proactive Offensive Content Filter for Twitter**

TweetShield is a real-time tweet moderation tool that detects hate speech and offensive language **before** a tweet is posted. Unlike traditional moderation systems that act *after* user reports, TweetShield takes a **proactive approach** to prevent harmful content from being published in the first place.

---

## ğŸš€ Features
- âš ï¸ **Real-time Tweet Scanning**
- ğŸ§  **Deep Learning-Based Classification** (Keras LSTM model)
- âœ… **Severity-Based Action**
  - **Block** for extreme cases
  - **Flag** for medium-level violations
- ğŸ¦ Integrated with **Twitter API**
- ğŸ”’ Designed to promote safer online spaces

---

## ğŸ› ï¸ Tech Stack
- **Python**
- **Keras / TensorFlow**
- **Twitter API (Tweepy)**
- **NLP Toolkit** â€“ Tokenization, stopword removal, TF-IDF

---



## ğŸ§ª How It Works

1. User attempts to post a tweet.
2. The tweet text is passed to the trained model.
3. Based on confidence score:
   - If **toxic**, the tweet is **blocked**.
   - If **potentially harmful**, the tweet is **flagged**.
   - Else, it's **allowed** to post.

---

## ğŸ“‚ Project Structure

